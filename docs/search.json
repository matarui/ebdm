{
  "articles": [
    {
      "path": "exam.html",
      "title": "Exam",
      "description": "What have you learned?",
      "author": [],
      "contents": "\n\nContents\nAssessment\n\nExams are learning instruments too… photo by Annie Spratt on UnsplashAssessment\nThe assessment will take place 22.5.23, 14:15-15:45 and will consist of an in-person multiple-choice exam.\nThe exam will be implemented on EvaExam and students will be asked to bring their own devices (BYOD principle) to complete the exam.\nWe will have a practice trial with this system on 24.04.23. Those students who experience problems during the practice trial or prefer a paper-pencil version of the exam should make a direct request to the instructor at least 2 weeks before the final exam date (22.5.23).\n\n\n\n",
      "last_modified": "2023-02-07T11:52:51+01:00"
    },
    {
      "path": "index.html",
      "title": "EBDM",
      "description": "Welcome to the website for *Evidence-based decision making* FS23 ([11230-01](https://vorlesungsverzeichnis.unibas.ch/de/home?id=263293))\n\nInstructor: [Rui Mata](https://psychologie.unibas.ch/de/personen/rui-mata/about-me/), University of Basel\n\n**WEBSITE UNDER CONSTRUCTION:** Last updated `r format(Sys.time(), \"%a %b %d %X %Y\")`\n",
      "author": [],
      "contents": "\n\nContents\nSession information\nWhat is this course about?\nWhat can you expect to learn?\nBy completing the course you can expect to LEARN…\nyou will NOT, however, receive training in…\n\nHow should you use this website?\n\nVery much like a spread of tools, science offers a plethora of strategies… photo by Cesar Carlevarino Aragon on UnsplashSession information\nSessions take place Mondays, 14.15-15.45, Biozentrum, Maurice E. Müller Saal U1.111.\n\n#\nDate\nTopic\n1\n20.02.2023\nThe scientific method(s)\n2\n06.03.2023\nAlgorithms: The power of algorithms\n3\n13.03.2023\nAlgorithms: The problems of algorithms\n4\n20.03.2023\nConsensus: The wisdom of the crowd\n5\n27.03.2023\nConsensus: The wisdom of experts\n6\n17.04.2023\nCounterfactuals: Experiments\n7\n24.04.2023\nCounterfactuals: Alternatives to experiments\n8\n08.05.2023\nSynthesis\n9\n15.05.2023\nInterventions\n10\n22.05.2023\nExam\n\nWhat is this course about?\nAs the name implies, this course is about evidence-based decision making. The main premise of the course is that informed decisions require the use of evidence (i.e., data that has been processed in some way to generate knowledge or insight).\nThe behavioral sciences, such as psychology and economics, have developed a number of concepts and techniques - a methodological toolbox - designed to transform data into evidence. This course aims to unpack some of these tools and showcase how they can be used in practice.\nThe overarching theme of the course is that evidence-based decision making uses the tools of SCIENCE to help us make better, informed decisions. This theme is reflected in the structure of the course: After the first introductory session, the course is divided into modules covering 5 different scientific “methods”, specifically, the benefits and limits of formalization (Algorithms), the discussion and amalgamation of diverse opinions (Consensus), the use of experiments and other methods to infer causality (Counterfactuals), the comprehensive and unbiased summary of multiple studies (Synthesis), and the implementation of interventions based on the best possible evidence (Interventions).\nWhat can you expect to learn?\nThe course will cover broad theoretical principles of evidence-based decision making. The principles will be illustrated with examples, inclduing at least one simple tutorial with example code in R, and other recommended exercises designed to facilitate understanding of the underlying concepts.\nBy completing the course you can expect to LEARN…\ncentral concepts in evidence-based decision making\ngeneral principles of causal inference\nbasic statistical concepts (e.g., aggregation, bias)\nguidelines for conducting and reporting scientific procedures\na taxonomy of behavioral interventions\nmany practical and positive examples of evidence-based practices\nyou will NOT, however, receive training in…\nmathematical analysis\nadvanced programming skills\nHow should you use this website?\nThis website is designed to help course participants get an overview of the course and access most course materials.\nEach session is structured such that some materials are available for preparation before the session (recommended readings, youtube videos). In addition, the slides of each presentation are made available. However, note that the final version of the slides will only be made available after each session.\nFinally, additional resources, such as optional exercises or background readings are listed at the end of each session for those that would like to learn more about the topic of the session.\nInformation about the exam is available on the Exam tab on this webpage.\n\n\n\n",
      "last_modified": "2023-02-07T11:52:52+01:00"
    },
    {
      "path": "lens_model_solutions.html",
      "title": "Exercise: Policy Capturing",
      "description": "Can algorithms help YOU make better decisions?",
      "author": [],
      "contents": "\n\nContents\nLoad libraries\nLoad data\n\nLoad libraries\n\n\nlibrary(tidyverse)\nlibrary(knitr)\n\n\nLoad data\n\n\ndata <- read.csv(url(\"https://github.com/matarui/ebdm/raw/main/materials/data.csv\"))\n\n\nHere’s the data we’re modeling…\n\n\nggplot(data,aes(x=crit,y=prediction)) +\n  geom_point() +\n  theme_minimal() +\n  facet_wrap(~code)\n\n\n\nHow well did YOUR “clinical” judgment do overall, that is, what is the correlation between your ratings and the criterion?\n\n\nmydata<-data %>% \n  filter(code==\"KMT\") \n\nmymodel=lm(prediction~-1+Data+Language+Social+Experience,data=mydata)\nsummary(mymodel)\n\n\nCall:\nlm(formula = prediction ~ -1 + Data + Language + Social + Experience, \n    data = mydata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.1000 -0.3625  0.4750  1.7125  2.5500 \n\nCoefficients:\n           Estimate Std. Error t value Pr(>|t|)   \nData         3.7000     0.9469   3.907  0.00208 **\nLanguage     1.4500     0.9469   1.531  0.15163   \nSocial       1.9500     0.9469   2.059  0.06185 . \nExperience   2.9500     0.9469   3.115  0.00893 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.117 on 12 degrees of freedom\nMultiple R-squared:  0.9058,    Adjusted R-squared:  0.8744 \nF-statistic: 28.84 on 4 and 12 DF,  p-value: 4.502e-06\n\ncor(mydata$crit,mydata$prediction)\n\n[1] 0.6549275\n\nThis amounts to achievement.\nHow much weight did YOU give each cue?\nThis amounts to the coefficients in the summary of the model above (e.g., Data, Language, Social, Experience).\nHow much better/worse does a regression model of YOUR judgments, an “actuarial model”, do relative to your “clinical” judgment? In other words, what is the correlation between the predictions of a model based on your ratings and the criterion?\nThe performance of a paramorphic model of your judgments amounts to bootstrapping. The difference between this model and your clinical judgment is how much better the algorithm does relative to your clinical judgment. The diff is given for everyone in the table below…\n\n\n\n\ncode\nachievement\nresponselinearity\nbootstrapping\ndiff\n1893\n0.94\n0.98\n0.96\n0.02\na2000&\n0.98\n1.00\n0.99\n0.00\nBrbSBD220306\n0.92\n0.97\n0.95\n0.03\nDMH\n0.81\n0.91\n0.89\n0.08\nGennie\n0.93\n0.99\n0.94\n0.01\nKMT\n0.65\n0.77\n0.85\n0.20\nMUEL\n0.93\n0.96\n0.97\n0.04\nPendler2020\n0.83\n0.98\n0.85\n0.02\n\n\n\n\n",
      "last_modified": "2023-02-07T11:52:53+01:00"
    },
    {
      "path": "lens_model.html",
      "title": "Exercise: Policy Capturing",
      "description": "Can algorithms help YOU make better decisions?",
      "author": [],
      "contents": "\n\nContents\nLoading packages\nReading in the data\nPlotting all data\nSelecting YOUR data\nModeling the ENVIRONMENT\nSo, can you answer these questions?\n\nThis exercise aims to help you learn about Brunswick’s lens model and policy capturing. The goal is to use linear regression to model your own judgments so that you can answer the questions at the bottom of this page. If you didn’t participate in the experiment you can still complete the exercise using one of your colleague’s data.\nYou can type the commands below into a new R file to load the necessary R libraries and retrieve the data (please note that copy and pasting may not always work because incorrect characters are copied in this process). After that, you will have to write your own code to use regression to model your own ratings (but I provide some example code below)…\nLoading packages\nYou will need a couple of R packages to do some data wrangling and plot things. For this you will have to load them using the command library(PACKAGENAME).\nNOTE: If you never used tidyverse before, you will have to install it first by using install.package(“PACKAGENAME”). Once you have installed the packages, it will be sufficent to use library(PACKAGENAME) at the start of each R session - no need to install it again each time.\n\n\nlibrary(tidyverse)\nlibrary(knitr)\n\n\nReading in the data\nI have uploaded the data on github so R can read the file directly from there.\n\n\ndata <- read.csv(url(\"https://github.com/matarui/ebdm/raw/main/materials/data.csv\"))\n\n\nPlotting all data\nPerhaps it is helpful to see all the data in one plot. The figure below plots the actual criterion on the x-axis against your ratings on the y-axis? Can you find the subplot with your own data? How did you do?\n\n\nggplot(data,aes(x=crit,y=prediction)) +\n  geom_point() +\n  theme_minimal() +\n  facet_wrap(~code)\n\n\n\nSelecting YOUR data\nYou can select your own data and plot it. In the example below I use the data from participant “JW2648”\n\n\nmydata<-data %>% \n  filter(code==\"KMT\") \n\nggplot(mydata,aes(x=crit,y=prediction)) +\n  geom_point() +\n  theme_minimal()\n\n\n\nModeling the ENVIRONMENT\nBefore you continue with modeling your data, perhaps it is helpful to understand the problem you were given (and recall how to run a regression in R). Each job candidate was described on 4 cues: Data skills, Language skills, Social skills, and Experience. On each cue, a candidate could score either “Ok” (0) or “Great” (1).\nNow, one can use a regression model to estimate the weight associated with each cue. In the model below, I am using a linear regression to assess how much weight to give each cue.\nNOTE: I’m cheating a little bit because I’m taking out the intercept in the model (this is what the “-1” does in the formula below; I actually know (because I constructed this example) that the intercept is 0 and can be ignored - and removing the intercept (i.e., setting it to 0) is helpful later when modeling the data because the cues are more easily interpretable.\n\n\nmodel_env=lm(crit~-1+Data+Language+Social+Experience,data=mydata)\nsummary(model_env)\n\n\nCall:\nlm(formula = crit ~ -1 + Data + Language + Social + Experience, \n    data = mydata)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-3.182e-15 -1.154e-16  3.300e-18  7.150e-17  2.191e-16 \n\nCoefficients:\n            Estimate Std. Error   t value Pr(>|t|)    \nData       4.000e+00  4.147e-16 9.645e+15   <2e-16 ***\nLanguage   3.000e+00  4.147e-16 7.234e+15   <2e-16 ***\nSocial     2.000e+00  4.147e-16 4.823e+15   <2e-16 ***\nExperience 1.000e+00  4.147e-16 2.411e+15   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.273e-16 on 12 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 1.512e+32 on 4 and 12 DF,  p-value: < 2.2e-16\n\nCan you interpret the coefficients presented above? What does the 4.000e+00 mean?\nPlease note that you can also get a “prediction” from the model, that is, the rating that the model suggests each candidate should obtain given the candidate’s cue profile - I do this below when I use the function predict(). Then, one can correlate the criterion (the values stored in mydata as the column “crit”) and the prediction from the model - for which I use the function cor() below.\n\n\nprediction<-predict(model_env)\n\ncor(mydata$crit,prediction)\n\n[1] 1\n\nThe correlation between the model prediction and the criterion is 1! This suggests that the linear model captures the environment perfectly (perhaps you noticed above that R even gives you a warning “essentially perfect fit: summary may be unreliable”). Why is this?\nWell, I picked an “easy” environment in which each cue gives you a round number of rating points (say 4 for the cue Data, as indicated in the coefficient estimated at 4.000e+00; with the other cues receiving the weight 3, 2, and 1). Further, there is no noise around this criterion: As you can seen in the table below, the worst candidate, Joana, has 0 points, while the best candidate, Tina, with “Great” on all four cues (4+3+2+1), gets exactly 10 points. Everyone else gets something in between…\n\nnames\nData\nLanguage\nSocial\nExperience\ncrit\nJoana\n0\n0\n0\n0\n0\nFilipa\n1\n0\n0\n0\n4\nSimone\n0\n1\n0\n0\n3\nUlrike\n1\n1\n0\n0\n7\nUte\n0\n0\n1\n0\n2\nRita\n1\n0\n1\n0\n6\nBettina\n0\n1\n1\n0\n5\nGuilia\n1\n1\n1\n0\n9\nFernande\n0\n0\n0\n1\n1\nMaria\n1\n0\n0\n1\n5\nBela\n0\n1\n0\n1\n4\nSalome\n1\n1\n0\n1\n8\nManuela\n0\n0\n1\n1\n3\nDominque\n1\n0\n1\n1\n7\nJule\n0\n1\n1\n1\n6\nTina\n1\n1\n1\n1\n10\n\nSo, can you answer these questions?\nNow, if you use the logic above (and similar code) using your ratings, can you answer the following three questions?\nHow well did YOUR “clinical” judgment do overall, that is, what is the correlation between your ratings and the criterion?\nHow much weight did YOU give each cue?\nHow much better/worse does a regression model of YOUR judgments, an “actuarial model”, do relative to your “clinical” judgment? In other words, what is the correlation between the predictions of a model based on your ratings and the criterion?\nIf you’re able to answer the questions above, you could try doing the same based on data from a few other students, do you get similar or different results?\nNOTE: It’s quite common to get some error messages when starting to use R, if you don’t understand R’s error messages, search Google for answers and potential solutions - it’s what data analysts do ALL THE TIME! Of course, let me know through the FAQ on ADAM if you get stuck - I’ll come to the rescue or walk you through it during one of the next sessions!!!\n\n\n\n",
      "last_modified": "2023-02-07T11:52:54+01:00"
    },
    {
      "path": "session10.html",
      "title": "Synthesis",
      "description": "How does one conduct and report a meta-analysis?",
      "author": [],
      "contents": "\n\nContents\nPRISMA\nAdditional task\nRecommended Reading\n\n\nphoto by William Warby on UnsplashPRISMA\nAre you familiar with the “Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA)” and the associated website?\nTake a few minutes to look into the website and read the paper by Page et al. (2021) referenced below (60 minutes), paying particular attention to the checklist and flow diagrams presented.\nDo you recognize important differences or similarities with the CONSORT guidelines discussed in Session 7?\n\nAdditional task\nPick a systematic literature search and/or meta-analysis that you are familiar with or search for one using an literature database of your choice. To what extent does the report follow the PRISMA guidelines?\nRecommended Reading\nPage, M. J., McKenzie, J. E., Bossuyt, P. M., Boutron, I., Hoffmann, T. C., Mulrow, C. D., et al. (2021). The PRISMA 2020 statement: An updated guideline for reporting systematic reviews. BMJ, 372, n71. http://doi.org/10.1136/bmj.n71\n\n\n\n",
      "last_modified": "2023-02-07T11:52:55+01:00"
    },
    {
      "path": "session11.html",
      "title": "Interventions",
      "description": "A taxonomy of interventions and their implementation",
      "author": [],
      "contents": "\n\nContents\nRecommended Readings\nSession Slides\n\nPill or no pill, that is the question… photo by Christina Victoria Craft on UnsplashRecommended Readings\nMichie, S., van Stralen, M. M., & West, R. (2011). The behaviour change wheel: A new method for characterising and designing behaviour change interventions. Implementation Science, 6(1), 42. http://doi.org/10.1186/1748-5908-6-42\nBauer, M. S., Damschroder, L., Hagedorn, H., Smith, J., & Kilbourne, A. M. (2015). An introduction to implementation science for the non-specialist. BMC Psychology, 3(1), 65–12. http://doi.org/10.1186/S40359-015-0089-9\nSession Slides\nPlease note these slides are from FS22 … updated versions for FS23 will be uploaded closer to the session date.\nFinding consensus\n\n\n",
      "last_modified": "2023-02-07T11:52:55+01:00"
    },
    {
      "path": "session12.html",
      "title": "Implementation science",
      "description": "How can interventions be implemented in real-world contexts?",
      "author": [],
      "contents": "\n\nContents\nRecommended Reading\n\nPhoto by Glenn Carstens-Peters on UnsplashRecommended Reading\nBauer, M. S., Damschroder, L., Hagedorn, H., Smith, J., & Kilbourne, A. M. (2015). An introduction to implementation science for the non-specialist. BMC Psychology, 3(1), 65–12. http://doi.org/10.1186/S40359-015-0089-9\n\n\n\n",
      "last_modified": "2023-02-07T11:52:56+01:00"
    },
    {
      "path": "session2.html",
      "title": "The Scientific Method(s)",
      "description": "Is there such a thing as THE scientific method?",
      "author": [],
      "contents": "\n\nContents\nWhat is the scientific method? And can we trust it?\nWhat should we do to fix (psychological) science?\nSlides\nAdditional Resources\nBackground readings\n\n\n\n## Session Preparation\nWhat is the scientific method? And can we trust it?\nWhat do YOU think? Do you trust science and scientists? If so, why?\nIn this session, we discuss how science works in general and some reasons we may find ourselves (dis)trusting science. We discuss issues surrounding the justification of knowledge and the scientific enterprise as well as the replication crisis in psychology (see below).\nAs preparation, please watch Naomi Oreskes’ TED talk “Why we should trust scientists” (ca. 20 minutes) to learn more about the scientific method(s) and her thoughts on whether this ensures the trustworthiness of science and scientists.\n\n\nWhat should we do to fix (psychological) science?\nAs discussed in the introductory session, the behavioral sciences, such as psychology, have been in the news in the past few years for the wrong reasons - think “replication crisis”! But what should we be doing to change the status quo? Read the paper by Munafò et al. (2017) (ca. 60 minutes) to learn about some possible solutions.\nMunafò, M. R., Nosek, B. A., Bishop, D. V. M., Button, K. S., Chambers, C. D., Sert, du, N. P., et al. (2017). A manifesto for reproducible science. Nature Human Behaviour, 1, 1–9. http://doi.org/10.1038/s41562-016-0021\nSlides\nWhat is the scientific method?Additional Resources\nBackground readings\nAre you interested in reading more about these topics? These books could be for you…\nOreskes, N. (2019). Why trust science? Princeton: Oxford. Princeton University Press. https://www.jstor.org/stable/j.ctvfjczxx\nRitchie, S. (2020). Science fictions: Exposing fraud, bias, negligence and hype in science. London: Bodley Head. https://www.sciencefictions.org\n\n\n\n",
      "last_modified": "2023-02-07T11:52:56+01:00"
    },
    {
      "path": "session3.html",
      "title": "Algorithms",
      "description": "Can algorithms make better decisions than humans?",
      "author": [],
      "contents": "\n\nContents\nSession Preparation\nDo algorithms make better decisions?\nRecommended Reading\n\nSession Slides\nAdditional Resources\nExercise\nBackground Reading\n\n\nLoving data…photo by Alexander Sinn on UnsplashSession Preparation\nDo algorithms make better decisions?\nPaul Meehl was a pioneer in proposing the use of algorithmic decision-making in many areas of psychology, including clinical diagnosis and prognosis. He introduced the distinction between clinical and actuarial (algorithmic) judgment or prediction.\nIf you’d like, you can travel back to 1989 and experience a portion of Meehl’s lecture at the University of Minnesota in which he introduces the issue of clinical vs. statistical prediction - click on the image below to find the lecture Philosophical Psychology Session #09, starting at timestamp 1:14:00).\n\nRecommended Reading\nIn this session we will discuss Meehl’s proposals and its implications for applied practice in the behavioral sciences and society at large. Please read the recommended reading below by Dawes, Faust, and Meehl (1989) (ca. 60 minutes) for an overview of Meehl and related work.\nDawes, R. M., Faust, D., & Meehl, P. E. (1989). Clinical versus actuarial judgment. Science, 243(4899), 1668–1674. http://doi.org/10.2307/1703476\nSession Slides\nPlease note these slides are from FS22 … updated versions for FS23 will be uploaded closer to the session date.\nAlgorithms for the win!Additional Resources\nExercise\nThis session provides an introduction to algorithmic decision-making, including a tour of the lens model and policy capturing. If you’d like to get a short “hands-on” intro to conducting “policy capturing” yourself, I suggest you participate in the online experiment “Job or Not?” and then, using your own responses (or those of your colleagues), answer the three questions listed here.\n\nBackground Reading\nAre you interested in a scathing critique of clinical prediction? This classic could be of interest…\nDawes, R. (1994). House of cards: Psychology and psychotherapy built on myth. New York: Free Press.\n\n\n\n",
      "last_modified": "2023-02-07T11:52:56+01:00"
    },
    {
      "path": "session4.html",
      "title": "Algorithms",
      "description": "What are the limits of algorithmic decision-making?",
      "author": [],
      "contents": "\n\nContents\nSession Preparation\nWeapons of math destruction!?!\nLessons from machine learning\n\nSession Slides\nAdditional Resources\nFurther Readings\n\n\nExcuse me, could please tell me the exact whereabouts of John Connor? photo by Mina FC on UnsplashSession Preparation\nWeapons of math destruction!?!\nAlgorithmic decision-making is not without problems…\nPlease watch Cathy O’Neil’s TED talk “The era of blind faith in big data must end” (ca. 14 minutes) to learn more about the dark side of outsorcing our decisions to algorithms.\nThe video will serve as a starting point for a discussion on the limits of algorithmic decision-making.\n\n\nLessons from machine learning\nHow can the behavioral sciences use insights from machine learning to generate insights about human behavior?\nRead Yarkoni and Westfall (2017) (ca. 120 minutes) to get an overview machine learning concepts and some of its pitfalls (e.g., overfitting) and associated solutions (e.g., cross-validation, regularization).\nYarkoni, T., & Westfall, J. (2017). Choosing prediction over explanation in psychology: Lessons from machine learning. Perspectives on Psychological Science, 12(6), 1100–1122. http://doi.org/10.1177/1745691617693393\nSession Slides\nPlease note these slides are from FS22 … updated versions for FS23 will be uploaded closer to the session date.\nThe problem(s) with algorithmsAdditional Resources\nFurther Readings\nAre you interested in learning more about problems of machine learning, including the so-called “aligment problem”? This book could be a good starting point…\nChristian, B. (2020). The alignment problem. New York: W.W. Norton & Company. https://brianchristian.org/the-alignment-problem/\n\n\n\n",
      "last_modified": "2023-02-07T11:52:57+01:00"
    },
    {
      "path": "session5.html",
      "title": "Consensus",
      "description": "The ignorance and wisdom of the crowd",
      "author": [],
      "contents": "\n\nContents\nWisdom of the crowd\nSession Slides\nAdditional Resources\nFurther Readings\n\n\n\n## Session Preparation\nWisdom of the crowd\nCheck out this video by Mehdi Moussaid for an introduction to the wisdom of the crowd…\n\n\nMannes, A. E., Soll, J. B., & Larrick, R. P. (2014). The wisdom of select crowds. Journal of Personality and Social Psychology, 107(2), 276–299. http://doi.org/10.1037/a0036677\nSession Slides\nPlease note these slides are from FS22 … updated versions for FS23 will be uploaded closer to the session date.\nFinding consensusAdditional Resources\nFurther Readings\nHere’s a popular science classic on the topic of wisdom of the crowds.\nSurowiecki, J. (2004). The wisdom of crowds. Anchor.\n\n\n\n",
      "last_modified": "2023-02-07T11:52:57+01:00"
    },
    {
      "path": "session6.html",
      "title": "Consensus",
      "description": "The wisdom of experts",
      "author": [],
      "contents": "\n\nContents\nSuperforecasting\nRecommended Reading\n\nSession Slides\nFurther Reading\n\n\nFinding experts is no trivial business… photo by Rita Morais on UnsplashSuperforecasting\nAre good forecasters born or made? How can one best design teams to produce better forecasts? In this session, we cover work from the Good Judgment Project that has focused on answering these questions. Check out an interview by Phil Tetlock for an introduction to this work.\n\n\nAlso, read Mellers & Tetlock (2019). (ca. 60 minutes) for an overview of the Good Judgment Project and its main insights.\nRecommended Reading\nMellers, B. A. & Tetlock, P. E. (2019). From discipline-centered rivalries to solution-centered science. American Psychologist, 74 (3), 290-300. http://doi: 10.1037/amp0000429\nSession Slides\nPlease note these slides are from FS22 … updated versions for FS23 will be uploaded closer to the session date.\nFinding consensusFurther Reading\nA popular science book on the Good Judgment Project is available:\nTetlock, P.E. & Gardner, D. (2015). Superforecasting: The art and science of prediction Crown Publishers. https://wsp.wharton.upenn.edu/book/superforecasting/\n\n\n\n",
      "last_modified": "2023-02-07T11:52:57+01:00"
    },
    {
      "path": "session7.html",
      "title": "Counterfactuals",
      "description": "How should one conduct and report experiments?",
      "author": [],
      "contents": "\n\nContents\nWhat is a Randomized Control Trial\nStandards…\nSession Slides\nFurther Reading\n\n\n\nExperiments create counterfactuals… photo by CHUTTERSNAP on UnsplashWhat is a Randomized Control Trial\nRandomized control trials are a type of experiment and are often said to be the gold standard for causal inference. Check this video of the Medical Research Council for a short introduction to RCTs (5 minutes).\n\n\nStandards…\nWhat are key aspects of RCT trials and how should they be reported? Are you familiar with the “Consolidated Standards of Reporting Trials” (CONSORT) and the associated website?\nTake a few minutes 30-60 minutes to look into the website, the history of CONSORT, and, most importantly, the CONSORT checklist. Do you find the checklist helpful? Which items of the checklist do you find most important, and why?\n\nSession Slides\nPlease note these slides are from FS22 … updated versions for FS23 will be uploaded closer to the session date.\nFinding consensusFurther Reading\nAre you interested in the history and development of RCTs? This piece provides an interesting historical overview, including some discussion of limitations of RCTs.\nBothwell, L.E., Greene, J.A., Podolsky, S.H., & Jones, D.S. (2016). Assessing the gold standard - Lessons from the history of RCTs. New England Journal of Medicine, 2, 374(22):2175-81. doi: 10.1056/NEJMms1604593.\n\n\n\n",
      "last_modified": "2023-02-07T11:52:58+01:00"
    },
    {
      "path": "session8.html",
      "title": "Counterfactuals",
      "description": "What alternatives do we have to experiments?",
      "author": [],
      "contents": "\n\nContents\nCounterfactuals, counterfactuals, counterfactuals everywhere\nRecommended Reading\nSession Slides\nFurther Reading\n\n\n\nSearching for counterfactuals… photo by Edi Libedinsky on UnsplashCounterfactuals, counterfactuals, counterfactuals everywhere\nThere are many ways to make inferences but most (all?!?) forms of causal inference involve some form of counterfactual. Take some time to learn about the concept of counterfactuals.\n\n\nRecommended Reading\nVarian, H. R. (2016). Causal inference in economics and marketing. Proceedings of the National Academy of Sciences of the United States of America, 113(27), 7310–7315. http://doi.org/10.1073/pnas.1510479113\nSession Slides\nPlease note these slides are from FS22 … updated versions for FS23 will be uploaded closer to the session date.\nFinding consensusFurther Reading\nHere’s a popular science book on the “new” science of causal inference:\nPearl, J. & Mackenzie, D. (2018). The book of why: The new science of cause and effect. Basic Books. https://www.basicbooks.com/titles/judea-pearl/the-book-of-why/9781541698963/\n\n\n\n",
      "last_modified": "2023-02-07T11:52:58+01:00"
    },
    {
      "path": "session9.html",
      "title": "Synthesis",
      "description": "What is research synthesis?",
      "author": [],
      "contents": "\n\nContents\nResearch Synthesis\nRecommended Reading\n\nPRISMA\nAdditional task\nRecommended Reading\nSession Slides\n\n\nKnowledge is all around us… photo by Luis Tosta on UnsplashResearch Synthesis\nWhy do we need synthesis?\n\n\nRead the paper by Gurevitch et al. (2018) for a quick overview of the history of research synthesis (60 minutes).\nRecommended Reading\nGurevitch, J., Koricheva, J., Nakagawa, S., & Stewart, G. (2018). Meta-analysis and the science of research synthesis. Nature, 555(7695), 175–182. http://doi.org/10.1038/nature25753\nPRISMA\nAre you familiar with the “Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA)” and the associated website?\nTake a few minutes to look into the website and read the paper by Page et al. (2021) referenced below (60 minutes), paying particular attention to the checklist and flow diagrams presented.\nDo you recognize important differences or similarities with the CONSORT guidelines discussed in Session 7?\n\nAdditional task\nPick a systematic literature search and/or meta-analysis that you are familiar with or search for one using an literature database of your choice. To what extent does the report follow the PRISMA guidelines?\nRecommended Reading\nPage, M. J., McKenzie, J. E., Bossuyt, P. M., Boutron, I., Hoffmann, T. C., Mulrow, C. D., et al. (2021). The PRISMA 2020 statement: An updated guideline for reporting systematic reviews. BMJ, 372, n71. http://doi.org/10.1136/bmj.n71\nSession Slides\nPlease note these slides are from FS22 … updated versions for FS23 will be uploaded closer to the session date.\nFinding consensus\n\n\n",
      "last_modified": "2023-02-07T11:52:59+01:00"
    }
  ],
  "collections": []
}

{
  "articles": [
    {
      "path": "exam.html",
      "title": "Exam",
      "description": "What have you learned?",
      "author": [],
      "contents": "\n\nContents\nAssessment\n\nPhoto by Annie Spratt on UnsplashAssessment\nThe assessment will consist of an exam. More information will be available at the start of the semester.\n\n\n\n",
      "last_modified": "2021-12-26T23:28:24+01:00"
    },
    {
      "path": "index.html",
      "title": "EBDM",
      "description": "Welcome to the website for *Evidence-based decision making* FS22 ([11230-01](https://vorlesungsverzeichnis.unibas.ch/de/home?id=263293))\n\nInstructor: [Rui Mata](https://psychologie.unibas.ch/de/personen/rui-mata/about-me/), University of Basel\n\n**Last updated:** `r format(Sys.time(), \"%a %b %d %X %Y\")`\n",
      "author": [],
      "contents": "\n\nContents\nSession information\nWhat is this course about?\nWhat can you expect to learn?\nBy completing the course you can expect to LEARN…\nyou will NOT, however, receive training in…\n\nHow should you use this website?\n\nPhoto by Cesar Carlevarino Aragon on UnsplashSession information\nSessions take place Tuesdays, 16.15-17.45. Currently, the course is planned to be held in person but a change to an online format is possible depending on the current epidemiological situation.\n\n#\nDate\nTopic\nSlides\n1\n22.02.2022\nThe Scientific Method(s)\npdf\n2\n01.03.2022\nAlgorithms\npdf\n3\n22.03.2022\nAlgorithms\npdf\n4\n29.03.2022\nConsensus\npdf\n5\n05.04.2022\nConsensus\npdf\n6\n12.04.2022\nCounterfactuals\npdf\n7\n19.04.2022\nCounterfactuals\npdf\n8\n26.04.2022\nSynthesis\npdf\n9\n03.05.2022\nSynthesis\npdf\n10\n10.05.2022\nInterventions\npdf\n11\n17.05.2022\nInterventions\npdf\n12\n24.05.2022\nExam\n\n\nWhat is this course about?\nAs the name implies, this course is about evidence-based decision making. The main premise of the course is that informed decisions require the use of evidence (i.e., data that has been processed in some way to generate knowledge or insight).\nThe behavioral sciences, such as psychology and economics, have developed a number of concepts and techniques - a methodological toolbox - designed to transfrom data into evidence. This course aims to unpack some of these tools and showcase how they can be used in practice.\nThe overarching theme of the course is that evidence-based decision making uses the tools of science to help us make better, informed decisions. This theme is reflected in the structure of the course: After the first two introductory sessions, the course is divided into modules covering 5 different scientific “methods”, specifically, the benefits and limits of formalization (Algorithms), the discussion and amalgamation of diverse opinions (Consensus), the use of experiments and other methods to infer causality (Counterfactuals), the comprehensive and unbiased summary of multiple studies (Synthesis), and the establishment of guidelines and interventions based on the best possible evidence (Interventions).\nWhat can you expect to learn?\nThe course will cover broad theoretical principles of evidence-based decision making. The principles will be illustrated with examples, that is, a few simple tutorials with example code in R, and other recommended exercises designed to facilitate understanding of the underlying concepts.\nBy completing the course you can expect to LEARN…\ncentral concepts in evidence-based decision making\ngeneral principles of causal inference\nbasic statistical concepts (e.g., aggregation, bias)\nguidelines for conducting and reporting scientific procedures\na taxonomy of behavioral interventions\nmany practical and positive examples of evidence-based practices\nyou will NOT, however, receive training in…\nmathematical analysis\nadvanced programming skills\nHow should you use this website?\nThis website is designed to help course participants get an overview of the course and access most course materials (e.g., recommended background readings and videos, additional non-mandatory readings). A number of other resources, however, are available. An FAQ forum is available on ADAM. If technically possible, the portions of the online sessions involving presentation by the instructor will be recorded and made available after each session on SWITCHtube. Information about the exam is available on the Exam tab on this webpage.\nCourse materials, such as readings or suggested preparation exercises, will be made available about one week before each session. The slides associated will be posted after each session but no video recording will be made available.\n\n\n\n\n\n",
      "last_modified": "2022-03-04T15:19:46+01:00"
    },
    {
      "path": "lens_model_solutions.html",
      "title": "Exercise: Policy Capturing",
      "description": "Can algorithms help YOU make better decisions?",
      "author": [],
      "contents": "\n\nContents\nLoad libraries\nLoad data\n\nLoad libraries\n\n\nlibrary(tidyverse)\nlibrary(knitr)\n\n\n\nLoad data\n\n\ndata <- read.csv(url(\"https://github.com/matarui/ebdm/raw/main/docs/materials/data.csv\"))\n\n\n\nHere’s the data we’re modeling…\n\n\nggplot(data,aes(x=crit,y=prediction)) +\n  geom_point() +\n  theme_minimal() +\n  facet_wrap(~code)\n\n\n\n\nHow well did YOUR “clinical” judgment do overall, that is, what is the correlation between your ratings and the criterion?\n\n\nmydata<-data %>% \n  filter(code==\"JW2648\") \n\nmymodel=lm(prediction~-1+Data+Language+Social+Experience,data=mydata)\nsummary(mymodel)\n\n\n\nCall:\nlm(formula = prediction ~ -1 + Data + Language + Social + Experience, \n    data = mydata)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.500 -0.500  0.000  0.625  1.000 \n\nCoefficients:\n           Estimate Std. Error t value Pr(>|t|)    \nData         3.5000     0.3651   9.585 5.65e-07 ***\nLanguage     2.0000     0.3651   5.477 0.000141 ***\nSocial       2.5000     0.3651   6.847 1.78e-05 ***\nExperience   2.5000     0.3651   6.847 1.78e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8165 on 12 degrees of freedom\nMultiple R-squared:  0.9858,    Adjusted R-squared:  0.9811 \nF-statistic: 208.5 on 4 and 12 DF,  p-value: 5.632e-11\n\ncor(mydata$crit,mydata$prediction)\n\n\n[1] 0.9054188\n\nThis amounts to achievement.\nHow much weight did YOU give each cue?\nThis amounts to the coefficients in the summary of the model above (e.g., Data, Language, Social, Experience).\nHow much better/worse does a regression model of YOUR judgments, an “actuarial model”, do relative to your “clinical” judgment? In other words, what is the correlation between the predictions of a model based on your ratings and the criterion?\nThe performance of a paramorphic model of your judgments amounts to bootstrapping. The difference between this model and your clinical judgment is how much better the algorithm does relative to your clinical judgment. The diff is given for everyone in the table below…\n\n\n\n\ncode\nachievement\nresponselinearity\nbootstrapping\ndiff\n0.o\n0.96\n0.97\n0.99\n0.03\n14897\n0.92\n0.97\n0.94\n0.02\nabc\n0.89\n0.98\n0.91\n0.02\nAEL16\n0.96\n0.97\n0.99\n0.03\nbrotundkäs\n0.95\n0.97\n0.98\n0.03\nJW2648\n0.91\n0.97\n0.94\n0.03\nl76K\n0.85\n0.89\n0.95\n0.10\nPNMV\n0.94\n0.98\n0.96\n0.02\n\n\n\n\n",
      "last_modified": "2021-12-26T23:28:26+01:00"
    },
    {
      "path": "lens_model.html",
      "title": "Exercise: Policy Capturing",
      "description": "Can algorithms help YOU make better decisions?",
      "author": [],
      "contents": "\n\nContents\nLoading packages\nReading in the data\nPlotting all data\nSelecting YOUR data\nModeling the ENVIRONMENT\nSo, can you answer these questions?\n\nThis exercise aims to help you learn about Brunswick’s lens model and policy capturing. The goal is to use linear regression to model your own judgments so that you can answer the questions at the bottom of this page. If you didn’t participate in the experiment you can still complete the exercise using one of your colleague’s data.\nYou can type the commands below into a new R file to load the necessary R libraries and retrieve the data (please note that copy and pasting may not always work because incorrect characters are copied in this process). After that, you will have to write your own code to use regression to model your own ratings (but I provide some example code below)…\nLoading packages\nYou will need a couple of R packages to do some data wrangling and plot things. For this you will have to load them using the command library(PACKAGENAME).\nNOTE: If you never used tidyverse before, you will have to install it first by using install.package(“PACKAGENAME”). Once you have installed the packages, it will be sufficent to use library(PACKAGENAME) at the start of each R session - no need to install it again each time.\n\n\nlibrary(tidyverse)\nlibrary(knitr)\n\n\n\nReading in the data\nI have uploaded the data on github so R can read the file directly from there.\n\n\ndata <- read.csv(url(\"https://github.com/matarui/ebdm/raw/main/docs/materials/data.csv\"))\n\n\n\nPlotting all data\nPerhaps it is helpful to see all the data in one plot. The figure below plots the actual criterion on the x-axis against your ratings on the y-axis? Can you find the subplot with your own data? How did you do?\n\n\nggplot(data,aes(x=crit,y=prediction)) +\n  geom_point() +\n  theme_minimal() +\n  facet_wrap(~code)\n\n\n\n\nSelecting YOUR data\nYou can select your own data and plot it. In the example below I use the data from participant “JW2648”\n\n\nmydata<-data %>% \n  filter(code==\"JW2648\") \n\nggplot(mydata,aes(x=crit,y=prediction)) +\n  geom_point() +\n  theme_minimal()\n\n\n\n\nModeling the ENVIRONMENT\nBefore you continue with modeling your data, perhaps it is helpful to understand the problem you were given (and recall how to run a regression in R). Each job candidate was described on 4 cues: Data skills, Language skills, Social skills, and Experience. On each cue, a candidate could score either “Ok” (0) or “Great” (1). Now, one can use a regression model to estimate the weight associated with each cue. In the model below, I am using a linear regression to assess how much weight to give each cue.\nNOTE: I’m cheating a little bit because I’m taking out the intercept in the model (this is what the “-1” does in the formula below; I actually know (because I constructed this example) that the intercept is 0 and can be ignored - and removing the intercept (i.e., setting it to 0) is helpful later when modeling the data because the cues are more easily interpretable.\n\n\nmodel_env=lm(crit~-1+Data+Language+Social+Experience,data=mydata)\nsummary(model_env)\n\n\n\nCall:\nlm(formula = crit ~ -1 + Data + Language + Social + Experience, \n    data = mydata)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-2.474e-15 -3.177e-16  6.174e-17  3.099e-16  9.148e-16 \n\nCoefficients:\n            Estimate Std. Error   t value Pr(>|t|)    \nData       4.000e+00  3.865e-16 1.035e+16   <2e-16 ***\nLanguage   3.000e+00  3.865e-16 7.761e+15   <2e-16 ***\nSocial     2.000e+00  3.865e-16 5.174e+15   <2e-16 ***\nExperience 1.000e+00  3.865e-16 2.587e+15   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.643e-16 on 12 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 1.74e+32 on 4 and 12 DF,  p-value: < 2.2e-16\n\nCan you interpret the coefficients presented above? What does the 4.000e+00 mean?\nPlease note that you can also get a “prediction” from the model, that is, the rating that the model suggests each candidate should obtain given the candidate’s cue profile - I do this below when I use the function predict(). Then, one can correlate the criterion (the values stored in mydata as the column “crit”) and the prediction from the model - for which I use the function cor() below.\n\n\nprediction<-predict(model_env)\n\ncor(mydata$crit,prediction)\n\n\n[1] 1\n\nThe correlation between the model prediction and the criterion is 1! This suggests that the linear model captures the environment perfectly (perhaps you noticed above that R even gives you a warning “essentially perfect fit: summary may be unreliable”). Why is this?\nWell, I picked an “easy” environment in which each cue gives you a round number of rating points (say 4 for the cue Data, as indicated in the coefficient estimated at 4.000e+00; with the other cues receiving the weight 3, 2, and 1). Further, there is no noise around this criterion: As you can seen in the table below, the worst candidate, Joana, has 0 points, while the best candidate, Tina, with “Great” on all four cues (4+3+2+1), gets exactly 10 points. Everyone else gets something in between…\n\nnames\nData\nLanguage\nSocial\nExperience\ncrit\nJoana\n0\n0\n0\n0\n0\nFilipa\n1\n0\n0\n0\n4\nSimone\n0\n1\n0\n0\n3\nUlrike\n1\n1\n0\n0\n7\nUte\n0\n0\n1\n0\n2\nRita\n1\n0\n1\n0\n6\nBettina\n0\n1\n1\n0\n5\nGuilia\n1\n1\n1\n0\n9\nFernande\n0\n0\n0\n1\n1\nMaria\n1\n0\n0\n1\n5\nBela\n0\n1\n0\n1\n4\nSalome\n1\n1\n0\n1\n8\nManuela\n0\n0\n1\n1\n3\nDominque\n1\n0\n1\n1\n7\nJule\n0\n1\n1\n1\n6\nTina\n1\n1\n1\n1\n10\n\nSo, can you answer these questions?\nNow, if you use the logic above (and similar code) using your ratings, can you answer the following three questions?\nHow well did YOUR “clinical” judgment do overall, that is, what is the correlation between your ratings and the criterion?\nHow much weight did YOU give each cue?\nHow much better/worse does a regression model of YOUR judgments, an “actuarial model”, do relative to your “clinical” judgment? In other words, what is the correlation between the predictions of a model based on your ratings and the criterion?\nIf you’re able to answer the questions above, you could try doing the same based on data from a few other students, do you get similar or different results?\nNOTE: It’s quite common to get some error messages when starting to use R, if you don’t understand R’s error messages, search Google for answers and potential solutions - it’s what data analysts do ALL THE TIME! Of course, let me know through the FAQ on ADAM if you get stuck - I’ll come to the rescue or walk you through it during one of the next sessions!!!\n\n\n\n",
      "last_modified": "2021-12-26T23:28:28+01:00"
    },
    {
      "path": "session10.html",
      "title": "Synthesis",
      "description": "How does one conduct and report a meta-analysis?",
      "author": [],
      "contents": "\n\nContents\nPRISMA\nAdditional task\nRecommended Reading\n\n\nPhoto by William Warby on UnsplashPRISMA\nAre you familiar with the “Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA)” and the associated website?\nTake a few minutes to look into the website and read the paper by Page et al. (2021) referenced below (60 minutes), paying particular attention to the checklist and flow diagrams presented.\nDo you recognize important differences or similarities with the CONSORT guidelines discussed in Session 7?\n\nAdditional task\nPick a systematic literature search and/or meta-analysis that you are familiar with or search for one using an literature database of your choice. To what extent does the report follow the PRISMA guidelines?\nRecommended Reading\nPage, M. J., McKenzie, J. E., Bossuyt, P. M., Boutron, I., Hoffmann, T. C., Mulrow, C. D., et al. (2021). The PRISMA 2020 statement: An updated guideline for reporting systematic reviews. BMJ, 372, n71. http://doi.org/10.1136/bmj.n71\n\n\n\n",
      "last_modified": "2021-12-26T23:28:28+01:00"
    },
    {
      "path": "session11.html",
      "title": "Interventions",
      "description": "A taxonomy of interventions",
      "author": [],
      "contents": "\n\nContents\nRecommended Reading\n\nPhoto by Christina Victoria Craft on UnsplashRecommended Reading\nMichie, S., van Stralen, M. M., & West, R. (2011). The behaviour change wheel: A new method for characterising and designing behaviour change interventions. Implementation Science, 6(1), 42. http://doi.org/10.1186/1748-5908-6-42\n\n\n\n",
      "last_modified": "2021-12-26T23:28:29+01:00"
    },
    {
      "path": "session12.html",
      "title": "Implementation science",
      "description": "How can interventions be implemented in real-world contexts?",
      "author": [],
      "contents": "\n\nContents\nCan psychology save lives?\n\nPhoto by Glenn Carstens-Peters on UnsplashCan psychology save lives?\nIn this session, Prof. Dr. Jutta Mata, University of Mannheim, will join us to tell us about how psychology can save lives! Jutta will also be available to answer questions about her work on health interventions and her role as a scientific expert in academic and non-academic contexts.\nPlease prepare 1 to 2 questions based on what you have learned throughout the semester about evidence-based decision making.\n\n\n\n\n",
      "last_modified": "2021-12-26T23:28:29+01:00"
    },
    {
      "path": "session2.html",
      "title": "The Scientific Method(s)",
      "description": "Is there such a thing as THE scientific method?",
      "author": [],
      "contents": "\n\nContents\nWhat is the scientific method? And can we trust it?\nWhat should we do to fix (psychological) science?\nRecommended Reading\nFurther Suggestions\n\n\nSometimes it is good to start with a question or two… Photo by Jon Tyson on UnsplashWhat is the scientific method? And can we trust it?\nWhat do YOU think? Do you trust science and scientists? If so, why?\nPlease watch Naomi Oreskes’ TED talk “Why we should trust scientists” (ca. 20 minutes) to learn more about the scientific method(s) and her thoughts on whether this ensures the trustworthiness of science and scientists.\n\n\nWhat should we do to fix (psychological) science?\nAs discussed in the introductory session, the behavioral sciences, such as psychology, have been in the news in the past few years for wrong reasons - think “replication crisis”! But what should we be doing to change the status quo? Read the paper by Munafò et al. (2017) (ca. 60 minutes) to learn about some emerging solutions.\nRecommended Reading\nMunafò, M. R., Nosek, B. A., Bishop, D. V. M., Button, K. S., Chambers, C. D., Sert, du, N. P., et al. (2017). A manifesto for reproducible science. Nature Human Behaviour, 1, 1–9. http://doi.org/10.1038/s41562-016-0021\nFurther Suggestions\nAre you interested in reading more about these topics? These books could be for you…\nOreskes, N. (2019). Why trust science? Princeton: Oxford. Princeton University Press. https://www.jstor.org/stable/j.ctvfjczxx\nRitchie, S. (2020). Science fictions: Exposing fraud, bias, negligence and hype in science. London: Bodley Head. https://www.sciencefictions.org\nRosling, H. (2018). Factfulness. Ten reasons we’re wrong about the world - and why things are better than you think. Sceptre: London. https://www.gapminder.org/factfulness-book/\n\n\n\n",
      "last_modified": "2022-02-22T15:15:44+01:00"
    },
    {
      "path": "session3.html",
      "title": "Algorithms",
      "description": "Can algorithms make better decisions than humans?",
      "author": [],
      "contents": "\n\nContents\nDo algorithms make better decisions?\nRecommended Reading\nOptional: Paul Meehl on “Clinical vs. Statistical Prediction”\nOptional: Exercise\n\n\nPhoto by Alexander Sinn on UnsplashDo algorithms make better decisions?\nPaul Meehl was a pioneer in proposing the use of algorithmic decision-making in many areas of psychology, including clinical diagnosis and prognosis.\nIn this session we will discuss Meehl’s proposals and its implications for applied practice in the behavioral sciences and society at large. Please read the recommended reading below by Dawes, Faust, and Meehl (1989) (ca. 60 minutes) for an overview of this work.\nRecommended Reading\nDawes, R. M., Faust, D., & Meehl, P. E. (1989). Clinical versus actuarial judgment. Science, 243(4899), 1668–1674. http://doi.org/10.2307/1703476\nOptional: Paul Meehl on “Clinical vs. Statistical Prediction”\nIf you’d like, you can also travel back to 1989 by clicking on the image below (ca. 27 minutes; SWITCHtube link) to experience a portion of Meehl’s lecture at the University of Minnesota in which he introduces the issue of clinical vs. statistical prediction.\n\nOptional: Exercise\nSession 3 provided an introduction to algorithmic decision-making, including a tour of the lens model and policy capturing.\nIf you’d like to get a short “hands-on” intro to conducting “policy capturing” yourself, I suggest you participate in the online experiment “Job or Not?” and then, using your own responses (or those of your colleagues), answer the three questions listed here.\nIf you’d like to see a set of solutions, click here.\n\n\n\n",
      "last_modified": "2021-12-26T23:28:29+01:00"
    },
    {
      "path": "session4.html",
      "title": "Algorithms",
      "description": "What are the limits of algorithmic decision-making?",
      "author": [],
      "contents": "\n\nContents\nLessons from machine learning\nRecommended Reading\n\nWeapons of math destruction!?\nFighting for algorithmic justice!\n\nPhoto by Mina FC on UnsplashLessons from machine learning\nHow can the behavioral sciences use insights from machine learning to generate insights about human behavior?\nRead Yarkoni and Westfall (2017) (ca. 120 minutes) to get an overview machine learning concepts and some of its pitfalls (e.g., overfitting) and associated solutions (e.g., cross-validation, regularization).\nRecommended Reading\nYarkoni, T., & Westfall, J. (2017). Choosing prediction over explanation in psychology: Lessons from machine learning. Perspectives on Psychological Science, 12(6), 1100–1122. http://doi.org/10.1177/1745691617693393\nWeapons of math destruction!?\nAlgorithmic decision-making is not without problems…\nPlease watch Cathy O’Neil’s TED talk “The era of blind faith in big data must end” (ca. 14 minutes) to learn more about the dark side of outsorcing our decisions to algorithms.\nThe video will serve as a starting point for a discussion on the limits of algorithmic decision-making in the 23.03.2021 session.\n\n\nFighting for algorithmic justice!\nIn the aftermath of our discussion, one question that came up was what to do about possible algorithmic injustice. Joy Buolamwini makes clear that one way forward is to fight algorithmic bias by prodding algorithms and curating the data that are fed to them inclusively.\n\n\n\n\n\n",
      "last_modified": "2021-12-26T23:28:30+01:00"
    },
    {
      "path": "session5.html",
      "title": "Consensus",
      "description": "The ignorance and wisdom of the crowd",
      "author": [],
      "contents": "\n\nContents\nWisdom of the crowd\n\nPhoto by CHUTTERSNAP on UnsplashWisdom of the crowd\nListen to Mehdi Moussaid for an introduction to the wisdom of the crowd…\n\n\n\n\n\n",
      "last_modified": "2021-12-26T23:28:30+01:00"
    },
    {
      "path": "session6.html",
      "title": "Consensus",
      "description": "The wisdom of experts",
      "author": [],
      "contents": "\n\nContents\nRecommended Reading\n\nPhoto by Rita Morais on UnsplashRecommended Reading\nMannes, A. E., Soll, J. B., & Larrick, R. P. (2014). The wisdom of select crowds. Journal of Personality and Social Psychology, 107(2), 276–299. http://doi.org/10.1037/a0036677\n\n\n\n",
      "last_modified": "2021-12-26T23:28:30+01:00"
    },
    {
      "path": "session7.html",
      "title": "Counterfactuals",
      "description": "How should one conduct and report experiments?",
      "author": [],
      "contents": "\n\nContents\nStandards…\nAn example of the importance of understanding RCTs\n\nPhoto by CHUTTERSNAP on UnsplashStandards…\nExperiments are often said to be the gold standard for causal inference. But what are key aspects of experimental studies and how should they be reported?\nAre you familiar with the “Consolidated Standards of Reporting Trials” (CONSORT) and the associated website?\nTake a few minutes 30-60 minutes to look into the website, the history of CONSORT, and, most importantly, the CONSORT checklist. Do you find the checklist helpful? Which items of the checklist do you find most important, and why?\n\nAn example of the importance of understanding RCTs\nYou have probably have heard of the efficacy of different vaccines. But what does the “efficacy rate” actually mean? Check out the video below to help discuss when/how the results of RCTs can be useful!\n\n\n\n\n\n",
      "last_modified": "2021-12-26T23:28:31+01:00"
    },
    {
      "path": "session8.html",
      "title": "Counterfactuals",
      "description": "What alternatives do we have to experiments?",
      "author": [],
      "contents": "\n\nContents\nRecommended Reading\n\nPhoto by Edi Libedinsky on UnsplashRecommended Reading\nVarian, H. R. (2016). Causal inference in economics and marketing. Proceedings of the National Academy of Sciences of the United States of America, 113(27), 7310–7315. http://doi.org/10.1073/pnas.1510479113\n\n\n\n",
      "last_modified": "2021-12-26T23:28:31+01:00"
    },
    {
      "path": "session9.html",
      "title": "Synthesis",
      "description": "What is research synthesis?",
      "author": [],
      "contents": "\n\nContents\nResearch Synthesis\nRecommended Reading\n\n\nPhoto by Luis Tosta on UnsplashResearch Synthesis\nRead the paper by Gurevitch et al. (2018) for a quick overview of the history of research synthesis (60 minutes).\nRecommended Reading\nGurevitch, J., Koricheva, J., Nakagawa, S., & Stewart, G. (2018). Meta-analysis and the science of research synthesis. Nature, 555(7695), 175–182. http://doi.org/10.1038/nature25753\n\n\n\n",
      "last_modified": "2021-12-26T23:28:31+01:00"
    }
  ],
  "collections": []
}
